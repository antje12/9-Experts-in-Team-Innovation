version: "3"
services:
  zookeeper:
    container_name: zookeeper
    image: confluentinc/cp-zookeeper:7.2.1
    ports:
      - 2181:2181
    restart: unless-stopped
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVERS: 192.168.8.13:2888:3888;192.168.8.12:2888:3888;192.168.8.10:2888:3888

  kafka:
    container_name: kafka
    image: confluentinc/cp-kafka:7.2.1
    ports:
      - 19092:19092
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_ZOOKEEPER_CONNECT: 192.168.8.13:2181,192.168.8.12:2181,192.168.8.10:2181
      KAFKA_PARTITION_ASSIGNMENT_STRATEGY: org.apache.kafka.clients.consumer.RoundRobinAssignor
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT"
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:19092
      KAFKA_ADVERTISED_LISTENERS: "INTERNAL://192.168.8.13:9092,EXTERNAL://host.docker.internal:19092"
    restart: unless-stopped
    depends_on:
      - zookeeper

  schema-registry:
    container_name: schema-registry
    image: confluentinc/cp-schema-registry:latest
    hostname: schema-registry
    restart: always
    depends_on:
      - kafka
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "192.168.8.13:9092,192.168.8.12:9092,192.168.8.10:9092"
      SCHEMA_REGISTRY_LISTENERS: "http://0.0.0.0:8081"
      SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_ORIGIN: '*'
      SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_METHODS: 'GET,POST,PUT,OPTIONS'

  kowl:
    container_name: kowl
    image: quay.io/cloudhut/kowl:master 
    ports:
      - 8080:8080
    restart: unless-stopped
    depends_on:
      - schema-registry
    environment:
      KAFKA_BROKERS: 192.168.8.13:9092,192.168.8.12:9092,192.168.8.10:9092
      KAFKA_SCHEMAREGISTRY_ENABLED: true
      KAFKA_SCHEMAREGISTRY_URLS: http://192.168.8.13:8081

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    restart: unless-stopped
    volumes:
      - datanode:/hadoop/dfs/data
    env_file:
      - ./hadoop-hive.env
    environment:
      SERVICE_PRECONDITION: "192.168.8.12:50070"
    ports:
      - "50075:50075"

  mongo.db:
    container_name: mongo.db
    image: mongo:latest
    ports:
      - 27017:27017
    volumes:
      - mongo.vol:/data/db
    restart: unless-stopped
    entrypoint: [ "/usr/bin/mongod", "--bind_ip_all", "--replSet", "dbrs" ]

  redis-server:
    image: redis
    restart: unless-stopped
    ports:
      - 6379:6379
    volumes:
      - ./AguardioEIT/RedisPlugin/redis.conf:/usr/local/etc/redis/redis.conf
    command: redis-server /usr/local/etc/redis/redis.conf

  api:
    build: 
      context: ./AguardioEIT
      dockerfile: Dockerfile
    restart: unless-stopped
    ports:
      - 8082:80
    depends_on:
      - mongo.db
    environment:
      - DOCKERIZED=true
  
  leak-sensor:
    container_name: leak-sensor
    build: ./kafkaProducer/leak_sensor
    restart: unless-stopped
    depends_on:
      - schema-registry

  shower-sensor:
    container_name: shower-sensor
    build: ./kafkaProducer/shower_sensor
    restart: unless-stopped
    depends_on:
      - schema-registry
 
volumes:
  mongo.vol:
    name: "mongo.vol"
  datanode:
    name: datanode
